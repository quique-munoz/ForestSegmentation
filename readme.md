---

# ğŸŒ¿ LiDARâ€“CÃ¡mara Vegetation Mapping Pipeline

Este proyecto permite **capturar sincronizadamente imÃ¡genes RGB y nubes de puntos LiDAR**, segmentar la vegetaciÃ³n mediante visiÃ³n por computador y **calcular la altura media de la hierba en 3D**, generando un **mapa interactivo** con geolocalizaciÃ³n GPS.

---

## ğŸ“¦ Estructura general del proyecto

```
forest_segmentation/
â”œâ”€â”€ config/                      
â”‚   â””â”€â”€ snapshot.yaml            # Archivo de configuraciÃ³n de los parÃ¡metros para la captura de datos
â”‚
â”œâ”€â”€ forest_segmentation/
â”‚   â”œâ”€â”€ map_interactive.py       # Genera mapa interactivo Folium filtrando los resultados
â”‚   â”œâ”€â”€ net_monitor_node.py      # MonitorizaciÃ³n de la cobertura de internet
â”‚   â”œâ”€â”€ process_individual.py    # Segmenta y calcula alturas de vegetaciÃ³n por tramos, para la Ãºltima captura
â”‚   â”œâ”€â”€ process.py               # Segmenta y calcula alturas de vegetaciÃ³n por tramos, para todas las capturas
â”‚   â”œâ”€â”€ snapshot_client.py       # Cliente ROS2 para la captura de datos
â”‚   â””â”€â”€ snapshot_action.py       # AcciÃ³n ROS2 para la captura de datos
â”‚
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ snapshot.launch.py       # Launcher para la captura de datos (action-client)
â”‚ 
â”œâ”€â”€ runs/checkpoint_best_ema.pth # Modelo RF-DETRSegPreview entrenado
â”‚ 
â””â”€â”€ snapshots/                   # Contiene los datos capturados y procesados
    â”œâ”€â”€ 2025-10-23_10-29-12/     # Formato de las carpetas de captura: AAAA-MM-DD_HH-MM-SS/
    â”‚   â”œâ”€â”€ *_image.png          # Imagen capturada por la cÃ¡mara
    â”‚   â”œâ”€â”€ *_points.npy         # Nube de puntos capturada por el LiDAR
    â”‚   â”œâ”€â”€ *_tf.json            # Transformaciones entre cÃ¡mara y LiDAR
    â”‚   â”œâ”€â”€ camera_info.json     # ParÃ¡metros intrinsecos de la cÃ¡mara
    â”‚   â””â”€â”€ processed/           # Contiene los archivos procesados: nubes de puntos, csv e imÃ¡genes
    â”‚       â”œâ”€â”€ smallveg_clean.npy
    â”‚       â”œâ”€â”€ veg_heights.xlsx
    â”‚       â””â”€â”€ vari_smallveg.png
    â”‚       â””â”€â”€ ...
    â””â”€â”€ maps/                    # Contiene lo relativo al mapa interactivo
        â”œâ”€â”€ veg_points.json      # HistÃ³rico de los puntos acumulados
        â””â”€â”€ veg_map.html
```

---

## ğŸš€ Captura de datos

Para capturar un **snapshot sincronizado** con imagen RGB, nube de puntos del LiDAR, coordenadas GPS y transformaciones entre cÃ¡mara y LiDAR:

```bash
ros2 launch forest_segmentation snapshot.launch.py
```

ğŸ‘‰ Esto genera una nueva carpeta en `snapshots/` con el formato `YYYY-MM-DD_HH-MM-SS/`, que contiene todos los datos necesarios para el procesamiento posterior. Captura una Ãºnica vez.

Para poder ejecutar las capturas en mÃºltiples ocasiones se ha desarrollado un **nodo servidor de acciones** que sincroniza **Imagen + LiDAR + GPS** y guarda un *snapshot* completo a disco, mÃ¡s un ejemplo de un nodo **cliente** que dispara capturas periÃ³dicas.

### Nodos

* **`snapshot_action`** (servidor)
  Publica la acciÃ³n **`/take_snapshot`** del paquete `forest_segmentation_interfaces`. Sincroniza:
  * `sensor_msgs/Image` en `image_topic`
  * `sensor_msgs/PointCloud2` en `lidar_topic`
  * `sensor_msgs/NavSatFix` en `gps_topic`
    y escucha `sensor_msgs/CameraInfo` en `caminfo_topic` (se guarda bajo demanda).  

* **`snapshot_client`** (cliente)
  EnvÃ­a goals periÃ³dicos a `/take_snapshot` con *slop* y la opciÃ³n de exigir `CameraInfo` **solo en el primer goal**. Evita solapar goals si uno sigue en curso. 

### Interfaz de la acciÃ³n `TakeSnapshot`

* **Goal**

  * `float32 sync_slop_sec` â€” tolerancia de sincronizaciÃ³n.
  * `bool require_caminfo` â€” si `true`, intenta guardar `camera_info.json` en ese snapshot.
* **Feedback**

  * `string state` â€” estados como `"syncing"`, `"saving"`. 
* **Result**

  * `bool success`, `string error`
  * `string output_dir`, `string basename`
  * `string image_path`, `points_path`, `gps_path`, `tf_path` 

### ParÃ¡metros

* **Cliente**

  * `period_sec` (float, default 15.0): periodo entre capturas. 
  * `sync_slop_sec` (float, default 0.1): *slop* por defecto para la sincronizaciÃ³n. 

### EjecuciÃ³n Manual (sin launcher)

1. **Servidor**

```bash
ros2 run forest_segmentation snapshot_action --ros-args --params-file snapshot.yaml
```

2. **Cliente** (capturas periÃ³dicas)

```bash
ros2 run forest_segmentation snapshot_client \
  --ros-args -p period_sec:=10.0 -p sync_slop_sec:=0.08
```

3. **Goal manual con CLI**

```bash
ros2 action send_goal /take_snapshot \
  forest_segmentation_interfaces/action/TakeSnapshot \
  "{sync_slop_sec: 0.05, require_caminfo: true}"
```

### Estructura de salida

Los snapshots se guardan en `forest_segmentation/snapshots/AAAA-MM-DD_HH-MM-SS/` con prefijo de *timestamp* de la imagen:

```
<fecha>_<hora>_<usec>_image.png
<fecha>_<hora>_<usec>_points.npy
<fecha>_<hora>_<usec>_gps.json
<fecha>_<hora>_<usec>_tf.json
camera_info.json        # si lo solicitaste en el goal
```

### Troubleshooting

* **â€œGoal en cursoâ€**: el cliente no envÃ­a un nuevo goal hasta que termine el anterior. Baja `period_sec` o evita tiempos muertos largos. 
* **Timeout esperando datos sincronizados**: revisa *topics* y sube `sync_slop_sec` si las fuentes no estÃ¡n bien alineadas. 
* **TF no encontrada** (`camera_leftâ†lidar`) : ajusta frames o publica la TF estÃ¡tica correspondiente. 

---

## ğŸŒ¾ Procesamiento y segmentaciÃ³n

Una vez capturados los datos, ejecuta:

```bash
python3 process.py
```

### ğŸ” Â¿QuÃ© hace este script (`process.py`)?

1. **Localiza automÃ¡ticamente** todos los snapshots en `snapshots/` segÃºn el nombre de la carpeta.
2. **Carga los datos**:

   * Imagen RGB (`*_image.png`)
   * Nube de puntos (`*_points.npy`)
   * Transformaciones cÃ¡maraâ€“LiDAR (`*_tf.json`)
   * ParÃ¡metros intrÃ­nsecos (`camera_info.json`)
3. **Aplica segmentaciÃ³n RF-DETR-SegPreview** para clasificar cada pÃ­xel segÃºn su clase:

   * `forest` â†’ vegetaciÃ³n alta (bosques)
   * `obstacle` â†’ obstÃ¡culos no previstos en el entorno (tendido elÃ©ctrico, seÃ±ales, vehÃ­culos...)
   * `rough` â†’ camino pedregoso
   * `sky` â†’ cielo
   * `smallveg` â†’ vegetaciÃ³n baja / media
   * `smooth` â†’ camino o superficie transitable
4. **Fusiona LiDAR + segmentaciÃ³n:**

   * Proyecta los puntos LiDAR sobre la imagen.
   * Asigna etiquetas 3D por clase (vegetaciÃ³n o camino).
   * Filtra outliers (altura y ruido) con `Open3D.remove_statistical_outlier`.
5. **Analiza la vegetaciÃ³n**:

   * Si hay suficientes puntos de camino (se establece un mÃ­nimo de 30):
     * Ajusta un **eje central del camino** (polinomio de grado 3).
     * Divide la vegetaciÃ³n en **izquierda / derecha**.
     * Calcula la altura por tramos de 0.1 m (z_max â€“ z_min).
     * Guarda las mÃ©tricas en `veg_heights.xlsx` (`left`, `right`).

   * Si **no hay camino** (off-road):
     * Analiza toda la vegetaciÃ³n como un solo bloque.
     * Guarda `veg_heights.xlsx` con hoja `all`.
8. **Ãndice VARI**:

   Calcula VARI (Visible Atmospherically Resistant Index) solo en pÃ­xeles `smallveg` y guarda un overlay como `vari_smallveg.png`.
7. **Llama automÃ¡ticamente** a `map_interactive.py` para actualizar el mapa.

---

## ğŸ—ºï¸ Mapa interactivo

Para generar o actualizar el mapa manualmente (si lo deseas):

```bash
python3 map_interactive.py /ruta/al/snapshot
```

### ğŸ§­ QuÃ© hace este script (`map_interactive.py`):

1. **Lee las mÃ©tricas** de `veg_heights.xlsx` del snapshot.
2. **Filtra valores no vÃ¡lidos** y alturas sin vegetaciÃ³n o con una altura Ã­nfima (`â‰¤ 0.05 m`).
3. **Calcula una altura combinada Ãºnica por snapshot:**

   * Si hay hoja `all` â†’ usa ese valor.
   * Si no, combina las alturas de las hojas `left` y `right` segÃºn la estrategia:

     * `"max"` (por defecto) â†’ peor caso, mÃ¡s conservador, mayor altura.
     * `"mean"` â†’ media simple.
     * `"weighted_mean"` â†’ media ponderada por nÃºmero de tramos vÃ¡lidos.
4. **Representa un solo marcador por snapshot**, con:

   * Color por severidad:

     | Altura (m) | Color      | Icono       | Nivel |
     | ---------- | ---------- | ----------- | ----- |
     | < 1.0      | ğŸŸ¢ Verde   | âœ… check     | Baja  |
     | 1.0 â€“ 2.0  | ğŸŸ  Naranja | âš ï¸ triangle | Media |
     | > 2.0      | ğŸ”´ Roja    | ğŸ”¥ fire     | Alta  |

   * Popup con los valores individuales (`left`, `right`, `all`) y media ponderada.
   * Estos marcadores se agrupan por severidad, permitiendo un control de capas segÃºn la altura de la vegetaciÃ³n.
5. **Heatmap de vegetaciÃ³n** aÃ±ade una capa de calor basada en la altura combinada normalizada.

6. **Dibuja la trayectoria del vehÃ­culo** conectando los snapshots con una lÃ­nea azul.

![](./media/map_view.png)

ğŸ—ºï¸ El mapa se guarda en:

```
snapshots/maps/veg_map.html
```

Ejemplo de popup:

```
ğŸ“ GPS: 33.475069, -88.790519
Altura vegetaciÃ³n (max): 1.85 m
--------------------------------
Left: 1.20 m (n=42)
Right: 1.85 m (n=36)
Weighted mean (L/R): 1.49 m
```

---

## ğŸ“ˆ Flujo completo

```mermaid
flowchart LR
    A[ROS2 snapshot_saver] -->|Imagen + Nube LiDAR + GPS| B[process_info.py]
    B -->|SegmentaciÃ³n RF-DETR + AnÃ¡lisis 3D| C[veg_heights.xlsx]
    C --> D[map_interactive.py]
    D --> E[veg_map.html]
    E --> F[Mapa interactivo + HistÃ³rico GPS]
```

---

## ğŸ“Š Resultados

Cada nueva ejecuciÃ³n de `process.py`:

* ğŸ“ Crea la carpeta `processed/` dentro del snapshot.
* ğŸ“Š Genera `veg_heights.xlsx` con las mÃ©tricas por lado o globales.
* ğŸŒ Actualiza `maps/veg_points.json` con un nuevo punto georreferenciado.
* ğŸ—ºï¸ AÃ±ade un marcador en el mapa `veg_map.html`.

El mapa acumula histÃ³ricos de varios snapshots, permitiendo visualizar la **evoluciÃ³n de la vegetaciÃ³n** y la **trayectoria del vehÃ­culo**.

---

## âš™ï¸ Dependencias principales

| LibrerÃ­a             | Uso                                |
| -------------------- | ---------------------------------- |
| **PyTorch**          | Inferencia del modelo RF-DETR      |
| **Open3D**           | Filtrado de nubes de puntos        |
| **Pandas / NumPy**   | Procesamiento numÃ©rico             |
| **Folium**           | VisualizaciÃ³n en mapa              |
| **Supervision**      | AnotaciÃ³n visual de segmentaciones |
| **RFDETRSegPreview** | Modelo de segmentaciÃ³n RF-DETR     |

InstalaciÃ³n recomendada:

```bash
pip install torch torchvision open3d folium supervision pandas pillow scipy
```

---

## ğŸ§¾ Resumen rÃ¡pido

| Etapa                      | Comando                                              | Resultado                                  |
| :------------------------- | :----------------------------------------------------| :----------------------------------------- |
| ğŸ“· Captura de snapshot     | `ros2 launch forest_segmentation snapshot.launch.py` | Carpeta con imagen, LiDAR y GPS            |
| ğŸŒ¿ SegmentaciÃ³n y anÃ¡lisis | `python3 process.py`                                 | SegmentaciÃ³n + mÃ©tricas + mapa actualizado |
| ğŸ—ºï¸ Ver mapa                | `snapshots/maps/veg_map.html`                        | Mapa Folium interactivo                    |

---

## ğŸ§  Notas adicionales

* Los snapshots se nombran automÃ¡ticamente con formato `YYYY-MM-DD_HH-MM-SS`.
* El mapa se actualiza automÃ¡ticamente tras cada procesamiento.
* Si no se detecta vegetaciÃ³n (`veg_heights.xlsx` no existe), el mapa conserva los puntos previos.
* En entornos off-road, la vegetaciÃ³n se analiza como un bloque Ãºnico (`all`).
* Los valores de altura usan una combinaciÃ³n robusta (IQR + MAD) que ignora tramos con altura â‰¤ 0.05 m.
* Los modelos de segmentaciÃ³n fueron entrenados con datos off-road reales del CAVS (Mississippi State University). https://www.cavs.msstate.edu/resources/autonomous_dataset.php

> Dabbiru, L., Sharma, S., Ennin, K.A., Goodin, C.T., Hudson, C.R., Doude, M., Carruth, D.W., & Ball, J.E.  
> *CAVS semantic segmentation dataset for off-road autonomous vehicles.*  
> Proceedings of SPIE 13474, Autonomous Systems: Sensors, Processing, and Security for Ground, Air, Sea, and Space Vehicles and Infrastructure, 14 April 2025.  
> DOI: [10.1117/12.3039888](https://doi.org/10.1117/12.3039888)

---

âœï¸ **Autor:** Quique MuÃ±oz
ğŸ“ **Repositorio:** `forest_segmentation`
ğŸ—“ï¸ **Ãšltima actualizaciÃ³n:** Diciembre 2025
